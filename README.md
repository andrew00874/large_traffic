Node.js를 이용한 대용량 트래픽 처리 실습 🚀
이 프로젝트는 Node.js 환경에서 대용량 트래픽을 효율적으로 처리하기 위한 두 가지 핵심 기술, **클러스터링(Clustering)**과 **캐싱(Caching)**의 원리를 이해하고 실습하는 것을 목표로 합니다.

<br>

📚 목차 (Table of Contents)
시작하기

실습 1: 클러스터링 (Clustering)

실습 2: 캐싱 (Caching)

<br>

⚙️ 시작하기 (Getting Started)
사전 준비 (Prerequisites)
Node.js가 설치되어 있어야 합니다.

Redis가 설치되어 있고, 실행 중이어야 합니다. (캐싱 실습 시 필요)

설치 (Installation)
프로젝트에 필요한 라이브러리들을 설치합니다.

Bash

npm install
<br>

🔬 실습 1: 클러스터링 (Clustering)
CPU 코어를 최대한 활용하여 서버의 동시 요청 처리량을 높이는 방법을 실습합니다.

💡 개념 (Concept)
Node.js는 기본적으로 싱글 스레드(Single-Threaded)로 작동하여 CPU 코어가 여러 개여도 하나만 사용합니다. 클러스터링은 CPU 코어 수만큼 프로세스를 복제(fork)하여 들어오는 요청을 여러 프로세스에 분산시키는 기술입니다. 이를 통해 서버의 자원을 최대한 활용하여 더 많은 요청을 동시에 처리할 수 있습니다.

💻 적용된 코드 (cluster_server.js)
마스터 프로세스(cluster.isPrimary)는 CPU 코어 개수만큼 워커 프로세스를 생성합니다.

생성된 각 워커 프로세스(else 블록)는 독립적으로 HTTP 서버를 실행하여 요청을 나누어 처리합니다.

워커 프로세스가 예기치 않게 종료되면, 마스터 프로세스가 이를 감지하고 새로운 워커를 생성하여 서비스의 안정성을 유지합니다. (cluster.on("exit"))

✅ 실습 방법 (How to Practice)
아래 명령어로 클러스터 서버를 실행합니다.

Bash

node cluster_server.js
터미널에 마스터 프로세스 ID와 CPU 개수, 그리고 실행된 워커들의 프로세스 ID(PID)가 출력되는 것을 확인합니다.

[마스터] 프로세스 ID: 12345
CPU 개수: 8개
[워커] 12346번 프로세스 실행 완료
[워커] 12347번 프로세스 실행 완료
...
웹 브라우저에서 http://localhost:3000 주소로 여러 번 접속하거나, curl 명령어를 반복해서 실행합니다.

요청할 때마다 서로 다른 프로세스 ID(process.pid)가 응답하는 것을 통해, 들어온 요청이 여러 워커 프로세스에 의해 분산 처리되고 있음을 직접 확인할 수 있습니다.

안녕하세요! 이 응답은 프로세스 12346에서 보냈습니다.
안녕하세요! 이 응답은 프로세스 12347에서 보냈습니다.
<br>

⚡ 실습 2: 캐싱 (Caching)
Redis를 캐시 저장소로 활용하여 느린 데이터베이스 조회를 대체하고, 빠른 응답 속도를 확보하는 방법을 실습합니다.

💡 개념 (Concept)
캐싱은 자주 요청되지만 자주 변경되지 않는 데이터를 데이터베이스보다 훨씬 빠른 메모리 기반 저장소에 임시로 보관하는 기술입니다. 클라이언트의 요청이 오면, 느린 데이터베이스까지 가지 않고 캐시에서 바로 데이터를 반환하여 응답 속도를 획기적으로 개선하고 데이터베이스의 부하를 줄여줍니다.

💻 적용된 코드 (cache_server.js)
Express.js 서버가 Redis 클라이언트를 생성하여 캐시 저장소로 연결합니다.

/data 엔드포인트로 요청이 오면, 가장 먼저 Redis에 데이터가 있는지 확인합니다. (Cache Hit)

만약 Redis에 데이터가 없다면(Cache Miss), 1.5초의 지연 시간을 시뮬레이션한 getSlowDataFromDB() 함수를 호출하여 데이터를 가져옵니다.

데이터베이스에서 가져온 데이터는 10초의 유효 기간과 함께 Redis에 저장(setEx)한 후, 클라이언트에게 응답합니다.

✅ 실습 방법 (How to Practice)
캐싱 실습을 위해 Redis 서버가 실행 중인지 반드시 확인합니다.

아래 명령어로 캐시 서버를 실행합니다.

Bash

node cache_server.js
새로운 터미널을 열고, curl http://localhost:3000/data 명령어를 실행하여 서버 로그와 응답 시간을 관찰합니다.

➡️ 첫 번째 요청:

서버 로그: Cache Miss! DB에서 데이터를 가져옵니다.가 출력됩니다.

응답 시간: 약 1.5초 후 데이터가 응답됩니다.

➡️ 두 번째 요청 (10초 이내):

서버 로그: Cache Hit! 응답을 캐시에서 가져옵니다.가 출력됩니다.

응답 시간: 거의 즉시 데이터가 응답됩니다.

➡️ 10초 경과 후 다시 요청:

캐시 유효 기간이 만료되었으므로, 다시 Cache Miss!가 발생하고 1.5초의 지연 시간이 소요됩니다.
