# 🚀 Node.js를 이용한 대용량 트래픽 처리 실습

이 프로젝트는 Node.js 환경에서 대용량 트래픽을 효율적으로 처리하기 위한 두 가지 핵심 기술, **클러스터링(Clustering)**과 **캐싱(Caching)**의 원리를 이해하고 실습하는 것을 목표로 합니다.

---

## 📚 목차

1. [시작하기](#시작하기-getting-started)
2. [실습 1: 클러스터링 (Clustering)](#실습-1-클러스터링-clustering)
3. [실습 2: 캐싱 (Caching)](#실습-2-캐싱-caching)

---

## ⚙️ 시작하기 (Getting Started)

### 📌 사전 준비 (Prerequisites)

- Node.js 설치
- Redis 설치 및 실행 (캐싱 실습 시 필요)

### 📦 설치 (Installation)

```bash
npm install
```

---

## 🔬 실습 1: 클러스터링 (Clustering)

### 💡 개념

Node.js는 기본적으로 **싱글 스레드(Single-Threaded)**로 작동하여 CPU 코어가 여러 개여도 하나만 사용합니다.  
**클러스터링**은 CPU 코어 수만큼 프로세스를 복제(`fork`)하여 들어오는 요청을 여러 프로세스에 분산시키는 기술입니다.  
이를 통해 서버 자원을 최대한 활용하여 더 많은 요청을 동시에 처리할 수 있습니다.

### 💻 적용 코드 (`cluster_server.js`)

- **마스터 프로세스 (`cluster.isPrimary`)**
  - CPU 코어 개수만큼 워커 프로세스를 생성
- **워커 프로세스 (`else` 블록)**
  - 독립적으로 HTTP 서버 실행
  - 요청 분산 처리
- **안정성 유지**
  - 워커 프로세스가 종료되면 새로운 워커를 재생성 (`cluster.on("exit")`)

### ✅ 실습 방법

```bash
node cluster_server.js
```

출력 예시:

```
[마스터] 프로세스 ID: 12345
CPU 개수: 8개
[워커] 12346번 프로세스 실행 완료
[워커] 12347번 프로세스 실행 완료
...
```

테스트 방법:

```bash
curl http://localhost:3000
```

응답 예시:

```
안녕하세요! 이 응답은 프로세스 12346에서 보냈습니다.
안녕하세요! 이 응답은 프로세스 12347에서 보냈습니다.
```

요청할 때마다 다른 PID가 반환됨 → 요청이 여러 워커로 분산 처리됨을 확인 가능.

---

## ⚡ 실습 2: 캐싱 (Caching)

### 💡 개념

**캐싱**은 자주 요청되지만 변경이 잦지 않은 데이터를  
데이터베이스 대신 **메모리 기반 저장소(Redis)**에 보관하여 빠르게 제공하는 기술입니다.  
이를 통해 응답 속도를 개선하고 DB 부하를 줄일 수 있습니다.

### 💻 적용 코드 (`cache_server.js`)

1. Express.js 서버에서 Redis 클라이언트를 생성 및 연결
2. `/data` 요청 시 처리 흐름:
   - **Cache Hit** → Redis에서 데이터 반환 (즉시 응답)
   - **Cache Miss** → 1.5초 지연 후 DB 시뮬레이션 → Redis에 10초 TTL로 저장 후 반환

### ✅ 실습 방법

1. Redis 서버 실행 확인
2. 캐시 서버 실행

```bash
node cache_server.js
```

3. 새로운 터미널에서 테스트

```bash
curl http://localhost:3000/data
```

#### 동작 예시

- **첫 번째 요청**
  ```
  서버 로그: Cache Miss! DB에서 데이터를 가져옵니다.
  응답 시간: 약 1.5초
  ```
- **10초 이내 두 번째 요청**
  ```
  서버 로그: Cache Hit! 응답을 캐시에서 가져옵니다.
  응답 시간: 거의 즉시
  ```
- **10초 경과 후 요청**
  ```
  서버 로그: Cache Miss!
  응답 시간: 약 1.5초
  ```

---

## 📌 요약

- **클러스터링** → CPU 코어 활용 극대화, 요청 처리량 증가
- **캐싱** → 응답 속도 향상, DB 부하 감소  
  이 두 가지 기술을 조합하면 대규모 트래픽 환경에서도 안정적이고 빠른 서비스 제공이 가능합니다.
